{
    "Title": "Tobias Burns",
    "SubTitle": "Software Developer",
    "Description": "Welcome to my website! My name is Tobias Burns, and I&#x27;m a recent transplant to Toronto from Ireland. On this website, you&#x27;ll find information about me, my interests, and my various projects. I have a passion for programming, music and gaming, and I enjoy working on interesting and exciting projects. On this site, you&#x27;ll find information about my background, as well as details about the projects I&#x27;ve worked on. The website is still under construction. It&#x27;s built using Blazor, and I have made the source code available on my GitHub page. In addition, you can find links to my social media accounts in the sidebar. Thank you for visiting my site, and I hope you enjoy learning more about me and my work.",
    "ImagePath": "staticData/profile.jpg",
    "SubSections": [
        {
            "Title": "Education",
            "SubTitle": null,
            "Description": null,
            "ImagePath": null,
            "SubSections": [
                {
                    "Title": "Study in pursuit of a PhD before exiting the program",
                    "SubTitle": "2017 - 2019 | Department of Computer Science, Maynooth University, Ireland | Deep Slam: Utilising Deep Learning for Predictive 3D Mapping, Supervisors: Dr. John McDonald &amp; Prof. Barak Pearlmutter",
                    "Description": "The past decade has seen a sea change in the capabilities of autonomous robotics. From self-driving cars to unmanned aerial vehicles, robots are moving out of the research lab and into our everyday lives. Central to these advances has been the development of visual sensing algorithms that allow robots to build 3D models of their environment from camera sensors. These models provide a foundation for higher level reasoning and interaction with the world, allowing robots to relate geometric, semantic and dynamic information about the environment. As such, the accuracy and completeness of these 3D models is critically important. In this project I am addressing two important problems with current visual mapping systems: their lack of semantic(object level) information, and their inability to model areas of the environment that they have not yet sensed. Although the latter seems like an impossible task, if we consider our own perception, we constantly deal with partial sensory information of the world, yet cognitively we are capable of bridging these gaps. The mechanism by which we recognise objects, and predict the unseen data to &quot;fill in gaps,&quot; is to use past experience of the world. I will develop algorithms with similar capabilities using an approach to machine learning, known as deep learning, to predict the class of objects and complete their structure based on partial data by learning object geometries from online 3D object databases. An important element here will be our approach to understanding uncertainties associated with the algorithm&#x27;s predictions. Firstly, this is important for processing itself, to know where more data is needed and to provide a confidence level in what the computer thinks it sees. Secondly, for humans using these systems, a representation of how reliable the system is, and how accurate the predicted regions of the map are, is extremely important.",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "Bachelor of Science (BSc), Computer Science and Software Engineering",
                    "SubTitle": "2013 - 2017 | Department of Computer Science, Maynooth University, Ireland",
                    "Description": "1st Class Honours 839/1000 Best in Class.",
                    "ImagePath": null,
                    "SubSections": []
                }
            ]
        },
        {
            "Title": "Awards and Funding",
            "SubTitle": null,
            "Description": null,
            "ImagePath": null,
            "SubSections": [
                {
                    "Title": "Intel Medal for Best Final Year Student in Computer Science",
                    "SubTitle": "Sept 2017 | Maynooth University",
                    "Description": "",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "John and Pat Hume Doctoral Scholarship",
                    "SubTitle": "Oct 2017 | Awarded by Maynooth University 2017",
                    "Description": "This provided ~â‚¬60,000 over 4 years to pursue my PhD.",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "SFI Research Grant",
                    "SubTitle": "May 2018 | Funded by Valeo and Lero - the Irish Software Research Centre",
                    "Description": "",
                    "ImagePath": null,
                    "SubSections": []
                }
            ]
        },
        {
            "Title": "Publications",
            "SubTitle": null,
            "Description": null,
            "ImagePath": null,
            "SubSections": [
                {
                    "Title": "MouldingNet: Deep-Learning for 3D Object Reconstruction",
                    "SubTitle": "2019 | T. Burns, B. Pearlmutter, and J. McDonald | Irish Machine Vision and Image Processing 2019, Technological University Dublin, Dublin, Ireland | doi:10.21427/synp-mr39",
                    "Description": "With the rise of deep neural networks a number of approaches for learning over 3D data have gained popularity. In this paper, we take advantage of one of these approaches, bilateral convolutional layers to propose a novel end-to-end deep auto-encoder architecture to efficiently encode and reconstruct 3D point clouds. Bilateral convolutional layers project the input point cloud onto an even tessellation of a hyperplane in the (<em>d</em> + 1)-dimensional space known as the permutohedral lattice and perform convolutions over this representation. In contrast to existing point cloud based learning approaches, this allows us to learn over the underlying geometry of the object to create a robust global descriptor. We demonstrate its accuracy by evaluating across the shapenet and modelnet datasets, in order to illustrate 2 main scenarios, known and unknown object reconstruction. These experiments show that our network generalises well from seen classes to unseen classes.",
                    "ImagePath": null,
                    "SubSections": []
                }
            ]
        },
        {
            "Title": "Work Experience",
            "SubTitle": null,
            "Description": null,
            "ImagePath": null,
            "SubSections": [
                {
                    "Title": "Software Engineer",
                    "SubTitle": "Apr 2020 - Jul 2022 | Susquehanna International Group, International Financial Services Centre, Co. Dublin, Ireland",
                    "Description": "<ul><li>Given complete ownership/control of a high volume desktop trading tool.</li><li>Designed, developed and supported business critical code using C# and the .NET framework.</li><li>Interviewed and mentored intern software engineers, helping them to develop their skills toward becoming full time hires.</li></ul>",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "Occasional Lecturer and Lab Demonstrator",
                    "SubTitle": "Feb 2017 - Dec 2019 | Maynooth University, Maynooth, Co. Kildare, Ireland",
                    "Description": "<ul><li>Demonstrated the modules &quot;Introduction to Object Oriented Programming&quot;, &quot;Algorithms and Data Structures&quot; and &quot;Software Design&quot;.</li><li>Guest lecturer for &quot;Software Design&quot;.</li></ul>",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "Robo Eireann Team Member",
                    "SubTitle": "Oct 2016 - Dec 2019 | Maynooth University, Maynooth, Co. Kildare, Ireland",
                    "Description": "<ul><li>Completed a project on visual robot detection, developed a system for visually detecting lines on a pitch and wrote the API wrapper for new camera hardware.</li><li>Attended Robocup 2017, Nagoya, Japan and took the role Team-Captain at Robocup 2019, Sydney, Australia.</li></ul>",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "Intern Software Engineer",
                    "SubTitle": "Feb 2016 - Aug 2016 | Accenture, 1 Grand Canal Square, Grand Canal Quay, Dublin 2, Ireland",
                    "Description": "<ul><li>Wrote reliable, efficient and maintainable code in C# and VB.</li><li>Worked closely with the companies business analysts and customers, handling shared requirements to meet deadlines and produce high quality software.</li></ul>",
                    "ImagePath": null,
                    "SubSections": []
                }
            ]
        },
        {
            "Title": "Project Abstracts",
            "SubTitle": null,
            "Description": null,
            "ImagePath": null,
            "SubSections": [
                {
                    "Title": "Final Year Project",
                    "SubTitle": "Oct 2016 - May 2017 | RoboCup - Visual Robot Detection",
                    "Description": "Robocup Soccer is an annual competition where teams of autonomous robots play soccer. Robo Eireann, the Maynooth University Robocup team, compete in the Standard Platform League where all robots have uniform hardware and so teams compete on a software level. Localisation, the problem of identifying where one is in a particular space, and object avoidance are two major issues in Robocup soccer. This project focused on improving Robo Eireann&#x27;s existing systems for performing these operations with the use of visual robot detection. Localisation currently relies on goal post detection which sometimes detects robots arms as false positives. This can have a significant negative impact on the robots behaviour and performance. By pre-filtering regions containing robots prior to goal detection the number of false positives would be greatly reduced. Object avoidance relies on sonar which has a very short range. Using a vision system to detect other robots is both longer range and more robust in terms of localisation. Previously the Robo Eireann robots had no system for visually detecting other robots. This project addressed this problem by applying the histogram of oriented gradients algorithm. This algorithm extracts a feature vector via the gradient orientation in local image regions. These features, along with a relevant classification label, are then fed into a support vector machine which is trained to perform robust robot detection. We found running a full histogram of oriented gradients on the images to be too slow due to the exhaustive nature of the search. To solve this problem a quick heuristic for finding candidate regions of an image had to be used. Discarded points from Robo Eireann&#x27;s ball detector tended to cluster around a robots legs. Using these points to create a bounding box around candidate regions increased the overall efficiency of our system. Our detector was trained and tested using 3-fold cross-validation on 200 images with a precision of 95% and a recall of 80%. To ensure that the outputs of the project could be exploited by Robo Eireann, a major component of the work focused on integration within the existing code base. The net result of this is a robot detection system that works both with Robo Eireann&#x27;s PC toolset and is deployable directly onto the Nao robot.",
                    "ImagePath": null,
                    "SubSections": []
                },
                {
                    "Title": "Robocup - Research Intern 2017",
                    "SubTitle": "Jun 2017 - Aug 2017 | Pitch Line Detection",
                    "Description": "Based on the success of my final year project described above I was offered a position on the Robo Eireann team as a research intern for 6 weeks. This internship allowed me to gain an understanding of advanced robotic software systems development and in particular the challenges of working with a team of researchers to create a unified real-time robotic software system. My main role was to develop systems for visually detecting lines on the pitch for use in localisation. As part of the internship I also travelled to Japan to participate in Robocup 2017 as a full team member for the competition. Since the internship I have continued as an active member of the team, staying involved in the platform development and a number of outreach activities over the current academic year.",
                    "ImagePath": null,
                    "SubSections": []
                }
            ]
        }
    ]
}